{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9e0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "import winsound\n",
    "from flask import Flask, render_template\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/run_eye_tracking')\n",
    "def run_eye_tracking():\n",
    "    def play_alarm():\n",
    "        #time.sleep(3)\n",
    "        frequency = 3500  # Set Frequency To 2500 Hertz\n",
    "        duration = 5000  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "   \n",
    "\n",
    "    # Define a function to calculate the eye aspect ratio\n",
    "    def eye_aspect_ratio(eye):\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "\n",
    "\n",
    "    \n",
    "    # Initialize dlib's face detector and create a dictionary to map facial landmark indexes to face parts\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    face_parts = face_utils.FACIAL_LANDMARKS_IDXS\n",
    "    (left_eye_start, left_eye_end) = face_parts[\"left_eye\"]\n",
    "    (right_eye_start, right_eye_end) = face_parts[\"right_eye\"]\n",
    "\n",
    "    # Start the video stream and wait for the camera to warm up\n",
    "    vs = cv2.VideoCapture(0)\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    # Initialize variables for calculating the attention level\n",
    "    drowsy_counter = 0\n",
    "    drowsy_threshold = 15\n",
    "    focused_counter = 0\n",
    "    focused_threshold = 5\n",
    "    unfocused_counter = 0\n",
    "    unfocused_threshold = 20\n",
    "    max_attention_level = \"unfocused\"\n",
    "    max_attention_time = time.time()\n",
    "    \n",
    "    eyes_closed = False\n",
    "\n",
    "    # Loop over frames from the video stream\n",
    "    while True:\n",
    "        # Read the next frame from the video stream and resize it\n",
    "        _, frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=450)\n",
    "    \n",
    "        # Convert the frame to grayscale and detect faces\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "    \n",
    "        # Reset the eye positions\n",
    "        left_eye_position = None\n",
    "        right_eye_position = None\n",
    "\n",
    "        # Loop over the face detections\n",
    "        for rect in rects:\n",
    "            # Determine the facial landmarks for the face region, then convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "            # Extract the left and right eye coordinates and compute the eye aspect ratio for each eye\n",
    "            left_eye = shape[left_eye_start:left_eye_end]\n",
    "            right_eye = shape[right_eye_start:right_eye_end]\n",
    "            left_eye_ear = eye_aspect_ratio(left_eye)\n",
    "            right_eye_ear = eye_aspect_ratio(right_eye)\n",
    "\n",
    "            # Compute the average eye aspect ratio\n",
    "            avg_ear = (left_eye_ear + right_eye_ear) / 2.0\n",
    "    \n",
    "            # Check if the average eye aspect ratio is below the drowsy threshold\n",
    "            if avg_ear < 0.25:\n",
    "                drowsy_counter += 1\n",
    "                focused_counter = 0\n",
    "                unfocused_counter = 0\n",
    "            else:\n",
    "                drowsy_counter = 0\n",
    "                focused_counter += 1\n",
    "                # Check if eyes are not in the frame\n",
    "                if left_eye.shape[0] == 0 or right_eye.shape[0] == 0:\n",
    "                    unfocused_counter += 1\n",
    "                else:\n",
    "                    left_eye_position = left_eye\n",
    "                    right_eye_position = right_eye\n",
    "\n",
    "            # Check if the attention level is drowsy\n",
    "            if drowsy_counter >= drowsy_threshold:\n",
    "                max_attention_level = \"drowsy\"\n",
    "                if drowsy_counter == drowsy_threshold:\n",
    "                    alarm_start_time = time.time()\n",
    "                if time.time() - alarm_start_time >= 3 and not eyes_closed:\n",
    "                    play_alarm()\n",
    "                    #eyes_closed = True\n",
    "                    drowsy_counter = 0\n",
    "            \n",
    "            # Check if the attention level is unfocused\n",
    "            if unfocused_counter >= unfocused_threshold:\n",
    "                max_attention_level = \"unattentive\"\n",
    "\n",
    "            # Check if the attention level is focused\n",
    "            if focused_counter >= focused_threshold:\n",
    "                max_attention_level = \"focused\"\n",
    "\n",
    "\t  \n",
    "\n",
    "     # Update the max attention level\n",
    "        if time.time() - max_attention_time >= 10:\n",
    "            print(f\"Max attention level for the past 10 Seconds : {max_attention_level}\")\n",
    "            max_attention_level = \"unattentive\"\n",
    "            max_attention_time = time.time()\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # If the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Cleanupq\n",
    "    cv2.destroyAllWindows()\n",
    "    #vs.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0fe0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
